<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>京东商品数据分布式抓取 | LearnDo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="采用 Scrapy 的 CrawlSpider 来实现爬虫。GitHub 地址 什么是 CrawlSpider ?class scrapy.spiders.CrawlSpider  用于爬取有一定规律的网站 定义了规则(rules)，提供方便跟进 link 的机制 适用于大多数情况，可以根据需要修改部分方法，当然也可以实现自己的 spider  除了从 Spider 继承过来的（必须提供的）属性外">
<meta name="keywords" content="爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="京东商品数据分布式抓取">
<meta property="og:url" content="http://yoursite.com/2018/04/19/京东商品数据分布式抓取/index.html">
<meta property="og:site_name" content="LearnDo">
<meta property="og:description" content="采用 Scrapy 的 CrawlSpider 来实现爬虫。GitHub 地址 什么是 CrawlSpider ?class scrapy.spiders.CrawlSpider  用于爬取有一定规律的网站 定义了规则(rules)，提供方便跟进 link 的机制 适用于大多数情况，可以根据需要修改部分方法，当然也可以实现自己的 spider  除了从 Spider 继承过来的（必须提供的）属性外">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-04-19T06:16:54.040Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="京东商品数据分布式抓取">
<meta name="twitter:description" content="采用 Scrapy 的 CrawlSpider 来实现爬虫。GitHub 地址 什么是 CrawlSpider ?class scrapy.spiders.CrawlSpider  用于爬取有一定规律的网站 定义了规则(rules)，提供方便跟进 link 的机制 适用于大多数情况，可以根据需要修改部分方法，当然也可以实现自己的 spider  除了从 Spider 继承过来的（必须提供的）属性外">
  
    <link rel="alternate" href="/atom.xml" title="LearnDo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LearnDo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-京东商品数据分布式抓取" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/19/京东商品数据分布式抓取/" class="article-date">
  <time datetime="2018-04-19T06:10:31.000Z" itemprop="datePublished">2018-04-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      京东商品数据分布式抓取
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>采用 Scrapy 的 CrawlSpider 来实现爬虫。<a href="https://github.com/kuz0/JDSpider" target="_blank" rel="noopener">GitHub 地址</a></p>
<h2 id="什么是-CrawlSpider"><a href="#什么是-CrawlSpider" class="headerlink" title="什么是 CrawlSpider ?"></a>什么是 CrawlSpider ?</h2><p><code>class scrapy.spiders.CrawlSpider</code></p>
<ul>
<li>用于爬取有一定规律的网站</li>
<li>定义了规则(rules)，提供方便跟进 link 的机制</li>
<li>适用于大多数情况，可以根据需要修改部分方法，当然也可以实现自己的 spider</li>
</ul>
<p>除了从 Spider 继承过来的（必须提供的）属性外，还提供了一个新的属性：</p>
<ul>
<li><p>rules</p>
<p>是<code>Rule</code>对象的集合。每个<code>Rule</code>对爬取网站定义了特定的行为。如果多个 rules 匹配了同一个链接，则根据它们在本属性中被定义的顺序，第一个会被使用。<a id="more"></a></p>
</li>
</ul>
<p><code>class scrapy.spiders.Rule(link_extractor, callback=None, cb_kwargs=None, follow=None, process_links=None, process_request=None)</code></p>
<ul>
<li><p>link_extractor：是一个 <strong>Link Extractor 对象</strong>，用于定义需要提取的链接 </p>
</li>
<li><p>callback：从 link_extractor 中每获取到链接时，参数所指定的值作为回调函数，该回调函数接受一个 response 作为其第一个参数 。</p>
<p>注意：当编写爬虫规则时，避免使用 parse 作为回调函数。由于 CrawlSpider 使用 parse 方法来实现其逻辑，如果覆盖了 parse 方法，crawl spider 将会运行失败</p>
</li>
<li><p>follow：是一个<strong>布尔值(boolean)</strong>，指定了根据该规则从 response 提取的链接是否需要跟进。 如果 callback 为 None，follow 默认设置为 True ，否则默认为 False </p>
</li>
<li><p>process_links：指定该 spider 中哪个的函数将会被调用，从 link_extractor 中获取到链接列表时将会调用该函数。该方法主要<strong>用来过滤</strong> </p>
</li>
<li><p>process_request：指定该 spider 中哪个的函数将会被调用， 该规则提取到每个 request 时都会调用该函数。 (用来<strong>过滤 request</strong>)</p>
</li>
</ul>
<p><code>scrapy.linkextractors.LinkExtractor</code> </p>
<p>主要参数：</p>
<ul>
<li>allow：满足括号中<strong>正则表达式</strong>的值会被提取，如果为空，则全部匹配 </li>
<li>deny：与这个<strong>正则表达式</strong>(或正则表达式列表)匹配的 URL 一定不提取 </li>
<li>allow_domains：<strong>会被提取</strong>的链接的 domains </li>
<li>deny_domains：<strong>一定不会被提取</strong>链接的 domains </li>
<li>restrict_xpaths：使用 xpath 表达式，和 allow 共同作用<strong>过滤链接</strong>。还有一个类似的 <strong>restrict_css</strong></li>
</ul>
<h2 id="CrawlSpider-如何工作？"><a href="#CrawlSpider-如何工作？" class="headerlink" title="CrawlSpider 如何工作？"></a>CrawlSpider 如何工作？</h2><ol>
<li>由 <strong>start_requests</strong> 对 <strong>start_urls</strong> 中的每一个 url 发起请求，这个请求会被 parse 接收 </li>
<li>在 Spider 里面的 parse 需要我们定义，但 CrawlSpider 定义 parse 去<strong>解析响应</strong>（self._parse_response(response, self.parse_start_url, cb_kwargs={}, follow=True)） </li>
<li>_parse_response 根据有无 <strong>callback</strong>，<strong>follow</strong> 和 <strong>self.follow_links</strong> 执行不同的操作 </li>
<li>其中 <strong>_requests_to_follow</strong> 又会获取 <strong>link_extractor</strong>（这个是传入的LinkExtractor）解析页面得到的<strong>link</strong>（link_extractor.extract_links(response)），对 url 进行加工（process_links，需要自定义），对符合的 link <strong>发起 Request</strong>。使用 process_request(需要自定义）处理响应</li>
</ol>
<h2 id="京东商品数据分布式爬取"><a href="#京东商品数据分布式爬取" class="headerlink" title="京东商品数据分布式爬取"></a>京东商品数据分布式爬取</h2><p>京东商品爬取难点在于全站信息，爬取全站所有信息的最好的方法就是使用通用爬虫 CrawlSpider。</p>
<h3 id="爬取步骤："><a href="#爬取步骤：" class="headerlink" title="爬取步骤："></a>爬取步骤：</h3><ol>
<li>浏览京东网站，寻找商品信息接口 </li>
<li>使用 LinkExtractor 抓取所有链接，用 allow_domains 限制爬取信息接口 </li>
<li>使用正则，抓取商品 id，拼接商品详情链接 </li>
<li>抓取商品详情以及价格 </li>
<li>尝试分布式爬取</li>
</ol>
<h3 id="代码部分："><a href="#代码部分：" class="headerlink" title="代码部分："></a>代码部分：</h3><ol>
<li>使用命令，建立 <strong>scrapy 文件</strong>以及 <strong>CrawlSpider 文件</strong></li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject jd</span><br><span class="line">cd jd</span><br><span class="line">scrapy genspider -t crawl jd_spider m.jd.com</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><p>编写 jd_spider.py 文件，该文件主要负责<strong>爬取链接</strong>以及<strong>商品详情信息</strong></p>
<p><a href="https://github.com/kuz0/JDSpider/blob/master/jd/spiders/jd_spider.py" target="_blank" rel="noopener">https://github.com/kuz0/JDSpider/blob/master/jd/spiders/jd_spider.py</a></p>
</li>
</ol>
<ol start="3">
<li><p>编写 pipeline.py，该文件主要<strong>负责入库</strong> </p>
<p><a href="https://github.com/kuz0/JDSpider/blob/master/jd/pipelines.py" target="_blank" rel="noopener">https://github.com/kuz0/JDSpider/blob/master/jd/pipelines.py</a></p>
</li>
</ol>
<ol start="4">
<li><p>编写 settings.py，该文件主要负责<strong>激活管道</strong>以及<strong>设置下载时间</strong></p>
<p><a href="https://github.com/kuz0/JDSpider/blob/master/jd/settings.py" target="_blank" rel="noopener">https://github.com/kuz0/JDSpider/blob/master/jd/settings.py</a></p>
</li>
</ol>
<ol start="5">
<li>添加分布式配置，再另外多台电脑上复制<strong>相同</strong>的一份代码，就可以实现多台同时爬取 </li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span>   <span class="comment">#必有项：更改去重对列</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Ensure all spiders share same duplicates filter through redis.</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span>   <span class="comment">#必有项：利用Redis去重</span></span><br><span class="line"></span><br><span class="line">REDIS_URL = <span class="string">'redis://xx.xx.xx.xx:xxxx'</span>   <span class="comment">#配置连接</span></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/19/京东商品数据分布式抓取/" data-id="cjg64tmxe0004oy7dxsa9etmi" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/04/15/Linux-Something/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Linux Something</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/">Git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyCharm/">PyCharm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ubuntu/">Ubuntu</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/PyCharm/" style="font-size: 10px;">PyCharm</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/爬虫/" style="font-size: 10px;">爬虫</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/04/19/京东商品数据分布式抓取/">京东商品数据分布式抓取</a>
          </li>
        
          <li>
            <a href="/2018/04/15/Linux-Something/">Linux Something</a>
          </li>
        
          <li>
            <a href="/2018/04/14/PyCharm-快捷键/">PyCharm 快捷键</a>
          </li>
        
          <li>
            <a href="/2018/04/13/Python-风格指南/">Python 风格指南</a>
          </li>
        
          <li>
            <a href="/2018/04/12/装饰器/">装饰器</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 kuz0<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>